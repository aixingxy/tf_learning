{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorFlow 测试样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0], name=\"a\")\n",
    "b = tf.constant([2.0, 3.0], name=\"b\")\n",
    "ADD = tf.add(a, b)\n",
    "sess = tf.Session()\n",
    "result = sess.run(ADD)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow程序一般可以分为两个阶段。在第一个阶段需要定义计算图中所有的计算，第二个阶段为执行计算。\n",
    "在TensorFlow程序中，系统会自动维护一个默认的计算图，通过tf.get_default_graph函数可以获得当前默认的计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了使用默认的计算图，Tensorflow支持通过tf.Graph函数来生成新的计算图。不同计算图上的张量和运算都不会共享。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'v:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'v:0' shape=(1,) dtype=float32_ref>\n",
      "[0.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# 在不同计算图上定义和使用变量\n",
    "import tensorflow as tf\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    # 在计算图g1中定义变量“v”，并设初始值为0.\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.zeros_initializer())\n",
    "    print(v)\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    # 在计算图g2中定义变量“v”，并设初始值为1.\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.ones_initializer())\n",
    "    print(v)\n",
    "    \n",
    "# 在计算图g1中读取变量“v”的取值\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    # 初始化变量节点，并运行\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "        \n",
    "# 在计算图g2中读取变量“v”的取值\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    # 初始化变量节点，并运行\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "# 在计算图g1中读取变量“v”的取值\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    # 初始化变量节点，并运行\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "        \n",
    "# init = tf.global_variables_initializer()\n",
    "# with tf.Session(graph=g1) as sess:\n",
    "#     sess.run(init)\n",
    "#     with tf.variable_scope(\"\", reuse=True):\n",
    "#         print(sess.run(tf.get_variable(\"v\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow计算图可以通过tf.Graph.device函数来指定运行计算机设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.device('/cpu:0'):\n",
    "    a = tf.constant([1.0, 2.0], name=\"a\")\n",
    "    b = tf.constant([2.0, 3.0], name=\"b\")\n",
    "    ADD = tf.add(a, b)\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(ADD)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_6:0\", shape=(2,), dtype=float32)\n",
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0], name=\"a\")\n",
    "b = tf.constant([2.0, 3.0], name=\"b\")\n",
    "ADD = tf.add(a, b)\n",
    "print(ADD)\n",
    "# 张量的三个属性：名字，维度，类型\n",
    "# 当类型不同会报错，如：a = tf.constant([1, 2], name=\"a\")\n",
    "sess = tf.Session()\n",
    "result = sess.run(ADD)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_11:0\", shape=(2,), dtype=float32)\n",
      "[3. 5.]\n",
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1.0, 2.0], name=\"a\")\n",
    "b = tf.constant([2.0, 3.0], name=\"b\")\n",
    "ADD = tf.add(a, b)\n",
    "print(ADD)\n",
    "sess = tf.Session()\n",
    "# 两种方法具有相同的功能\n",
    "print(sess.run(ADD))\n",
    "print(ADD.eval(session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor(\"Add_10:0\", shape=(2,), dtype=float32)\n",
    "[3. 5.]\n",
    "[3. 5.]\n",
    "\"Add_10:0\":说明了ADD这个张量是计算节点\"add\"输出的第一个结果（编号从0开始）\n",
    "shape=(2,):说明张量ADD是一个一维数组，这个数组的长度是2\n",
    "dtype=float32:张量的属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_Variable与Variablede 区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable的用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: firstvar:0\n",
      "var1: firstvar_1:0\n",
      "var2: Variable:0\n",
      "var2: Variable_1:0\n",
      "Var1= 2.0\n",
      "var2= 4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "var1 = tf.Variable(1.0, name='firstvar')\n",
    "print(\"var1:\", var1.name)\n",
    "var1 = tf.Variable(2.0, name='firstvar')\n",
    "print(\"var1:\", var1.name)\n",
    "var2 = tf.Variable(3.0)\n",
    "print(\"var2:\", var2.name)\n",
    "var2 = tf.Variable(4.0)\n",
    "print(\"var2:\", var2.name)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Var1=\", var1.eval())\n",
    "    print(\"var2=\", var2.eval())\n",
    "#     print(\"Var1=\", sess.run(var1))\n",
    "#     print(\"var2=\", sess.run(var2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_Variable的用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_var1: firstvar_2:0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable firstvar already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-2-cb0a3afdfb31>\", line 2, in <module>\n    get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.3))\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cb0a3afdfb31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"get_var1:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_var1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_var1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"firstvar\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"get_var1:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_var1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1047\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1050\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1051\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    339\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    651\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 653\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    654\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable firstvar already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-2-cb0a3afdfb31>\", line 2, in <module>\n    get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.3))\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.3))\n",
    "print (\"get_var1:\",get_var1.name)\n",
    "\n",
    "get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.4))\n",
    "print (\"get_var1:\",get_var1.name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"get_var1=\",get_var1.eval())\n",
    "    \n",
    "'''\n",
    "可以看到程序在定义第二个get_var1时发生崩溃了。这表明使用get_variable只能定义一次指定名称的变量。\n",
    "同时由于变量firstvar在之前用Variable生成过一次，所以系统自动变成了firstvar_2:0。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: firstvar:0\n",
      "var1: firstvar_1:0\n",
      "var2: Variable:0\n",
      "var2: Variable_1:0\n",
      "Var1= 2.0\n",
      "var2= 4.0\n",
      "get_var1: firstvar_2:0\n",
      "get_var1: firstvar1:0\n",
      "get_var1= [0.4]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "var1 = tf.Variable(1.0, name='firstvar')\n",
    "print(\"var1:\", var1.name)\n",
    "var1 = tf.Variable(2.0, name='firstvar')\n",
    "print(\"var1:\", var1.name)\n",
    "var2 = tf.Variable(3.0)\n",
    "print(\"var2:\", var2.name)\n",
    "var2 = tf.Variable(4.0)\n",
    "print(\"var2:\", var2.name)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Var1=\", var1.eval())\n",
    "    print(\"var2=\", var2.eval())\n",
    "get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.3))\n",
    "print (\"get_var1:\",get_var1.name)\n",
    "\n",
    "get_var2 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.4))\n",
    "print (\"get_var1:\",get_var1.name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"get_var1=\",get_var1.eval())\n",
    "'''\n",
    "仍然定义个get_var1，不同的是他的名字变成了firstvar1，这样就没问题了。\n",
    "同样，新的get_var1会在图中生效，所以它的输出值是4.0。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_var1: firstvar:0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable firstvar already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-1-b0218c1a17c1>\", line 2, in <module>\n    get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.3))\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b0218c1a17c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"get_var1:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_var1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_var2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"firstvar\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"get_var1:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_var1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1047\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1050\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1051\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    339\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    651\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 653\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    654\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable firstvar already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-1-b0218c1a17c1>\", line 2, in <module>\n    get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.3))\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/Users/xxy/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "get_var1 = tf.get_variable(\"firstvar\",[1], initializer=tf.constant_initializer(0.3))\n",
    "print (\"get_var1:\",get_var1.name)\n",
    "\n",
    "get_var1 = tf.get_variable(\"firstvar2\",[1], initializer=tf.constant_initializer(0.4))\n",
    "print (\"get_var1:\",get_var1.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在特定的作用域下获取变量\n",
    "使用get_variable，以及嵌套variable_scope\n",
    "由上面的例子知道，使用get_variable创建两个同样名字（name）的变量的（即name相同不行，变量名相同则覆盖）是行不通的。下面的代码会报错，如果真的想这么做，可以使用variable_scope将他们隔开。\n",
    "```python\n",
    "var1 = tf.get_variable(\"firstvar\", [2], dtype=tf.float32)\n",
    "var2 = tf.get_variable(\"firstvar\",[2], dtype=tf.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: test1/firstvar:0\n",
      "var2: test2/firstvar:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nvar1和var2都使用firstvar的名字来定义，在两个不同的作用域，生成两个不同的变量。\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隔开\n",
    "import tensorflow as tf\n",
    "with tf.variable_scope(\"test1\"):\n",
    "    var1 = tf.get_variable(\"firstvar\", [2], dtype=tf.float32)\n",
    "with tf.variable_scope(\"test2\"):\n",
    "    var2 = tf.get_variable(\"firstvar\", [2], dtype=tf.float32)\n",
    "print(\"var1:\", var1.name)\n",
    "print(\"var2:\", var2.name)\n",
    "'''\n",
    "var1和var2都使用firstvar的名字来定义，在两个不同的作用域，生成两个不同的变量。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: test1/firstvar:0\n",
      "var2: test1/test2/firstvar:0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "scope支持嵌套\n",
    "'''\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"test1\"):\n",
    "    var1 = tf.get_variable(\"firstvar\", [2], dtype=tf.float32)\n",
    "    with tf.variable_scope(\"test2\"):\n",
    "        var2 = tf.get_variable(\"firstvar\", [2], dtype=tf.float32)\n",
    "print(\"var1:\", var1.name)\n",
    "print(\"var2:\", var2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用作用域中reuse参数实现共享变量的功能。\n",
    "variable_scope里面有个reuse=True属性，表示使用已经定义过的变量。\n",
    "此时在使用get_variable将不会创建新的变量，而是去计算图中get_variable所创建的变量中找到与name相同的变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1/var1_name:0\n",
      "test1/test2/var1_name:0\n",
      "test1/var1_name:0\n",
      "test1/test2/var1_name:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.get_variable在创建变量的时候 ，回去检查图（一个计算任务）中是否已经创建过该变量。\n",
    "# 如果创建过并且本次调用时没有被设置为共享方式就会报错。\n",
    "# 调用tf.reset_default_graph()，将图（一个计算任务）里面的变量清空。\n",
    "tf.reset_default_graph() \n",
    "with tf.variable_scope(\"test1\"):\n",
    "    var1 = tf.get_variable(\"var1_name\", [1], dtype=tf.float32)\n",
    "    with tf.variable_scope(\"test2\"):\n",
    "        var2 = tf.get_variable(\"var1_name\", [1], dtype=tf.float32)\n",
    "    \n",
    "print(var1.name)\n",
    "print(var2.name)\n",
    "\n",
    "with tf.variable_scope(\"test1\", reuse=True):\n",
    "    var3 = tf.get_variable(\"var1_name\", [1], dtype=tf.float32)\n",
    "    with tf.variable_scope(\"test2\"):\n",
    "        var4 = tf.get_variable(\"var1_name\", [1], dtype=tf.float32) \n",
    "        \n",
    "print(var3.name)\n",
    "print(var4.name)\n",
    "\n",
    "#通过设置tf.variable_scope的reuse参数，来对作用域下的指定name的变量进行共享。\n",
    "#var1和var3的输出名字是一样的，var2和var3输出的名字是一样的，这就实现了变量的共享。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化共享变量的作用域——继承\n",
    "演示variable_scope中get_variable初始化的继承功能，以及嵌套variable_scope的继承功能。\n",
    "variable_scop和get_variable都要初始化功能。在初始化时，如果没有对当前变量初始化，则TensorFlow会默认使用作用域的初始化方法对其初始化，并且作用域的初始化方法也有继承功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1: [0.4 0.4]\n",
      "var2: [0.4 0.4]\n",
      "var3: [0.3 0.3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"test1\", initializer=tf.constant_initializer(0.4)): # 将test1作用域进行初始化为4.0\n",
    "    var1 = tf.get_variable(\"firstvar\", shape=[2], dtype=tf.float32) # var1没有初始化\n",
    "    with tf.variable_scope(\"test2\"): # 嵌套的test2作用域也没有初始化\n",
    "        var2 = tf.get_variable(\"firstvar\", shape=[2], dtype=tf.float32) # var1没有初始化\n",
    "        var3 = tf.get_variable(\"var3\", shape=[2], initializer=tf.constant_initializer(0.3)) # var3进行了初始化\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"var1:\", var1.eval())\n",
    "    print(\"var2:\", var2.eval())\n",
    "    print(\"var3:\", var3.eval())\n",
    "# 从结果看，var1数组为0.4，表明继承了test1的中值；\n",
    "# var2数组值为0.4，表明其所在的作用域也继承了test1的初始化；\n",
    "# 变量var3在创建时同步指定了初始化操作。所以数组值为0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：**在多模型训练中，常常会使用variable_scope对模型间张量进行区分。同时，统一为学习参数进行默认的初始化。在变量共享方面，还可以使用tf.AUTO_REUSE来为reuse属性赋值。tf.AUTO_REUSE可以实现第一次调用variable_scope时，传入的reuse值是False;再次调用variable_scope时，传入reuse的值就会自动变为True**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演示作用域与操作符的受限范围——with tf.variable_scope(\"scope1\") as sp\n",
    "演示variable_scope的as用法，以及对应的作用域。\n",
    "variable_scope还可以使用with variable_scope(\"name\") as xxxscope的方式定义作用域，当使用这种方式时，所定义的作用域变量xxxscope将不再受到外围scope所限制，就是继承失效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp: scope1\n",
      "var1: scope1/v:0\n",
      "sp1: scope1\n",
      "var2: scope2/v:0\n",
      "var3: scope1/v3:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"scope1\") as sp: # \n",
    "    var1 = tf.get_variable(\"v\", [1])\n",
    "print(\"sp:\", sp.name)\n",
    "print(\"var1:\", var1.name)\n",
    "\n",
    "with tf.variable_scope(\"scope2\"):\n",
    "    var2 = tf.get_variable(\"v\", [1])\n",
    "    \n",
    "    with tf.variable_scope(sp) as sp1: # sp1在scope2下，但是输出仍是scope1，没有改变。\n",
    "        var3 = tf.get_variable(\"v3\", [1]) # 在sp1下面定义的var3名字是scope1/v3:0，表明sp没有受到外层的限制\n",
    "\n",
    "print(\"sp1:\", sp1.name)\n",
    "print(\"var2:\", var2.name)\n",
    "print(\"var3:\", var3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 操作符作用域——tf.name_scope\n",
    "操作符不仅受到tf.name_scope作用域的限制，同时也受到tf.variable_scope作用域的限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v: scope/v:0\n",
      "x.op scope/bar/add\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(\"scope\"):\n",
    "    with tf.name_scope(\"bar\"):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "        x = 1.0 + v\n",
    "print(\"v:\", v.name)\n",
    "print(\"x.op\", x.op.name)\n",
    "# 可以看出，虽然v和x都在scope的bar下面，但是v的命名只受到scope的限制，\n",
    "# tf.name_scope只能限制op，不能限制变量的命名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在tf.name_scope函数中，还可以使用空字符将作用域返回到顶层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图的基本操作\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
